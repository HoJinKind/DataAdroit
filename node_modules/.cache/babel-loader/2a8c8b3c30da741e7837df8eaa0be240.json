{"ast":null,"code":"import stream from 'stream';\nimport React, { Component } from 'react';\nimport PropTypes from 'prop-types';\n\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n\n  return obj;\n}\n\nfunction _inherits(subClass, superClass) {\n  if (typeof superClass !== \"function\" && superClass !== null) {\n    throw new TypeError(\"Super expression must either be null or a function\");\n  }\n\n  subClass.prototype = Object.create(superClass && superClass.prototype, {\n    constructor: {\n      value: subClass,\n      writable: true,\n      configurable: true\n    }\n  });\n  if (superClass) _setPrototypeOf(subClass, superClass);\n}\n\nfunction _getPrototypeOf(o) {\n  _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) {\n    return o.__proto__ || Object.getPrototypeOf(o);\n  };\n  return _getPrototypeOf(o);\n}\n\nfunction _setPrototypeOf(o, p) {\n  _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) {\n    o.__proto__ = p;\n    return o;\n  };\n\n  return _setPrototypeOf(o, p);\n}\n\nfunction _assertThisInitialized(self) {\n  if (self === void 0) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n\n  return self;\n}\n\nfunction _possibleConstructorReturn(self, call) {\n  if (call && (typeof call === \"object\" || typeof call === \"function\")) {\n    return call;\n  }\n\n  return _assertThisInitialized(self);\n}\n\nvar commonjsGlobal = typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};\n\nfunction createCommonjsModule(fn, module) {\n  return module = {\n    exports: {}\n  }, fn(module, module.exports), module.exports;\n}\n\nvar papaparse = createCommonjsModule(function (module, exports) {\n  /* @license\n  Papa Parse\n  v4.6.2\n  https://github.com/mholt/PapaParse\n  License: MIT\n  */\n  // Polyfills\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/isArray#Polyfill\n  if (!Array.isArray) {\n    Array.isArray = function (arg) {\n      return Object.prototype.toString.call(arg) === '[object Array]';\n    };\n  }\n\n  (function (root, factory) {\n    /* globals define */\n    {\n      // Node. Does not work with strict CommonJS, but\n      // only CommonJS-like environments that support module.exports,\n      // like Node.\n      module.exports = factory();\n    }\n  })(commonjsGlobal, function () {\n    var global = function () {\n      // alternative method, similar to `Function('return this')()`\n      // but without using `eval` (which is disabled when\n      // using Content Security Policy).\n      if (typeof self !== 'undefined') {\n        return self;\n      }\n\n      if (typeof window !== 'undefined') {\n        return window;\n      }\n\n      if (typeof global !== 'undefined') {\n        return global;\n      } // When running tests none of the above have been defined\n\n\n      return {};\n    }();\n\n    var IS_WORKER = !global.document && !!global.postMessage,\n        IS_PAPA_WORKER = IS_WORKER && /(\\?|&)papaworker(=|&|$)/.test(global.location.search),\n        LOADED_SYNC = false,\n        AUTO_SCRIPT_PATH;\n    var workers = {},\n        workerIdCounter = 0;\n    var Papa = {};\n    Papa.parse = CsvToJson;\n    Papa.unparse = JsonToCsv;\n    Papa.RECORD_SEP = String.fromCharCode(30);\n    Papa.UNIT_SEP = String.fromCharCode(31);\n    Papa.BYTE_ORDER_MARK = '\\ufeff';\n    Papa.BAD_DELIMITERS = ['\\r', '\\n', '\"', Papa.BYTE_ORDER_MARK];\n    Papa.WORKERS_SUPPORTED = !IS_WORKER && !!global.Worker;\n    Papa.SCRIPT_PATH = null; // Must be set by your code if you use workers and this lib is loaded asynchronously\n\n    Papa.NODE_STREAM_INPUT = 1; // Configurable chunk sizes for local and remote files, respectively\n\n    Papa.LocalChunkSize = 1024 * 1024 * 10; // 10 MB\n\n    Papa.RemoteChunkSize = 1024 * 1024 * 5; // 5 MB\n\n    Papa.DefaultDelimiter = ','; // Used if not specified and detection fails\n    // Exposed for testing and development only\n\n    Papa.Parser = Parser;\n    Papa.ParserHandle = ParserHandle;\n    Papa.NetworkStreamer = NetworkStreamer;\n    Papa.FileStreamer = FileStreamer;\n    Papa.StringStreamer = StringStreamer;\n    Papa.ReadableStreamStreamer = ReadableStreamStreamer;\n\n    if (typeof PAPA_BROWSER_CONTEXT === 'undefined') {\n      Papa.DuplexStreamStreamer = DuplexStreamStreamer;\n    }\n\n    if (global.jQuery) {\n      var $ = global.jQuery;\n\n      $.fn.parse = function (options) {\n        var config = options.config || {};\n        var queue = [];\n        this.each(function (idx) {\n          var supported = $(this).prop('tagName').toUpperCase() === 'INPUT' && $(this).attr('type').toLowerCase() === 'file' && global.FileReader;\n          if (!supported || !this.files || this.files.length === 0) return true; // continue to next input element\n\n          for (var i = 0; i < this.files.length; i++) {\n            queue.push({\n              file: this.files[i],\n              inputElem: this,\n              instanceConfig: $.extend({}, config)\n            });\n          }\n        });\n        parseNextFile(); // begin parsing\n\n        return this; // maintains chainability\n\n        function parseNextFile() {\n          if (queue.length === 0) {\n            if (isFunction(options.complete)) options.complete();\n            return;\n          }\n\n          var f = queue[0];\n\n          if (isFunction(options.before)) {\n            var returned = options.before(f.file, f.inputElem);\n\n            if (typeof returned === 'object') {\n              if (returned.action === 'abort') {\n                error('AbortError', f.file, f.inputElem, returned.reason);\n                return; // Aborts all queued files immediately\n              } else if (returned.action === 'skip') {\n                fileComplete(); // parse the next file in the queue, if any\n\n                return;\n              } else if (typeof returned.config === 'object') f.instanceConfig = $.extend(f.instanceConfig, returned.config);\n            } else if (returned === 'skip') {\n              fileComplete(); // parse the next file in the queue, if any\n\n              return;\n            }\n          } // Wrap up the user's complete callback, if any, so that ours also gets executed\n\n\n          var userCompleteFunc = f.instanceConfig.complete;\n\n          f.instanceConfig.complete = function (results) {\n            if (isFunction(userCompleteFunc)) userCompleteFunc(results, f.file, f.inputElem);\n            fileComplete();\n          };\n\n          Papa.parse(f.file, f.instanceConfig);\n        }\n\n        function error(name, file, elem, reason) {\n          if (isFunction(options.error)) options.error({\n            name: name\n          }, file, elem, reason);\n        }\n\n        function fileComplete() {\n          queue.splice(0, 1);\n          parseNextFile();\n        }\n      };\n    }\n\n    if (IS_PAPA_WORKER) {\n      global.onmessage = workerThreadReceivedMessage;\n    } else if (Papa.WORKERS_SUPPORTED) {\n      AUTO_SCRIPT_PATH = getScriptPath(); // Check if the script was loaded synchronously\n\n      if (!document.body) {\n        // Body doesn't exist yet, must be synchronous\n        LOADED_SYNC = true;\n      } else {\n        document.addEventListener('DOMContentLoaded', function () {\n          LOADED_SYNC = true;\n        }, true);\n      }\n    }\n\n    function CsvToJson(_input, _config) {\n      _config = _config || {};\n      var dynamicTyping = _config.dynamicTyping || false;\n\n      if (isFunction(dynamicTyping)) {\n        _config.dynamicTypingFunction = dynamicTyping; // Will be filled on first row call\n\n        dynamicTyping = {};\n      }\n\n      _config.dynamicTyping = dynamicTyping;\n      _config.transform = isFunction(_config.transform) ? _config.transform : false;\n\n      if (_config.worker && Papa.WORKERS_SUPPORTED) {\n        var w = newWorker();\n        w.userStep = _config.step;\n        w.userChunk = _config.chunk;\n        w.userComplete = _config.complete;\n        w.userError = _config.error;\n        _config.step = isFunction(_config.step);\n        _config.chunk = isFunction(_config.chunk);\n        _config.complete = isFunction(_config.complete);\n        _config.error = isFunction(_config.error);\n        delete _config.worker; // prevent infinite loop\n\n        w.postMessage({\n          input: _input,\n          config: _config,\n          workerId: w.id\n        });\n        return;\n      }\n\n      var streamer = null;\n\n      if (_input === Papa.NODE_STREAM_INPUT && typeof PAPA_BROWSER_CONTEXT === 'undefined') {\n        // create a node Duplex stream for use\n        // with .pipe\n        streamer = new DuplexStreamStreamer(_config);\n        return streamer.getStream();\n      } else if (typeof _input === 'string') {\n        if (_config.download) streamer = new NetworkStreamer(_config);else streamer = new StringStreamer(_config);\n      } else if (_input.readable === true && isFunction(_input.read) && isFunction(_input.on)) {\n        streamer = new ReadableStreamStreamer(_config);\n      } else if (global.File && _input instanceof File || _input instanceof Object) // ...Safari. (see issue #106)\n        streamer = new FileStreamer(_config);\n\n      return streamer.stream(_input);\n    }\n\n    function JsonToCsv(_input, _config) {\n      // Default configuration\n\n      /** whether to surround every datum with quotes */\n      var _quotes = false;\n      /** whether to write headers */\n\n      var _writeHeader = true;\n      /** delimiting character(s) */\n\n      var _delimiter = ',';\n      /** newline character(s) */\n\n      var _newline = '\\r\\n';\n      /** quote character */\n\n      var _quoteChar = '\"';\n      /** whether to skip empty lines */\n\n      var _skipEmptyLines = false;\n      unpackConfig();\n      var quoteCharRegex = new RegExp(_quoteChar, 'g');\n      if (typeof _input === 'string') _input = JSON.parse(_input);\n\n      if (Array.isArray(_input)) {\n        if (!_input.length || Array.isArray(_input[0])) return serialize(null, _input, _skipEmptyLines);else if (typeof _input[0] === 'object') return serialize(objectKeys(_input[0]), _input, _skipEmptyLines);\n      } else if (typeof _input === 'object') {\n        if (typeof _input.data === 'string') _input.data = JSON.parse(_input.data);\n\n        if (Array.isArray(_input.data)) {\n          if (!_input.fields) _input.fields = _input.meta && _input.meta.fields;\n          if (!_input.fields) _input.fields = Array.isArray(_input.data[0]) ? _input.fields : objectKeys(_input.data[0]);\n          if (!Array.isArray(_input.data[0]) && typeof _input.data[0] !== 'object') _input.data = [_input.data]; // handles input like [1,2,3] or ['asdf']\n        }\n\n        return serialize(_input.fields || [], _input.data || [], _skipEmptyLines);\n      } // Default (any valid paths should return before this)\n\n\n      throw 'exception: Unable to serialize unrecognized input';\n\n      function unpackConfig() {\n        if (typeof _config !== 'object') return;\n\n        if (typeof _config.delimiter === 'string' && !Papa.BAD_DELIMITERS.filter(function (value) {\n          return _config.delimiter.indexOf(value) !== -1;\n        }).length) {\n          _delimiter = _config.delimiter;\n        }\n\n        if (typeof _config.quotes === 'boolean' || Array.isArray(_config.quotes)) _quotes = _config.quotes;\n        if (typeof _config.skipEmptyLines === 'boolean' || typeof _config.skipEmptyLines === 'string') _skipEmptyLines = _config.skipEmptyLines;\n        if (typeof _config.newline === 'string') _newline = _config.newline;\n        if (typeof _config.quoteChar === 'string') _quoteChar = _config.quoteChar;\n        if (typeof _config.header === 'boolean') _writeHeader = _config.header;\n      }\n      /** Turns an object's keys into an array */\n\n\n      function objectKeys(obj) {\n        if (typeof obj !== 'object') return [];\n        var keys = [];\n\n        for (var key in obj) keys.push(key);\n\n        return keys;\n      }\n      /** The double for loop that iterates the data and writes out a CSV string including header row */\n\n\n      function serialize(fields, data, skipEmptyLines) {\n        var csv = '';\n        if (typeof fields === 'string') fields = JSON.parse(fields);\n        if (typeof data === 'string') data = JSON.parse(data);\n        var hasHeader = Array.isArray(fields) && fields.length > 0;\n        var dataKeyedByField = !Array.isArray(data[0]); // If there a header row, write it first\n\n        if (hasHeader && _writeHeader) {\n          for (var i = 0; i < fields.length; i++) {\n            if (i > 0) csv += _delimiter;\n            csv += safe(fields[i], i);\n          }\n\n          if (data.length > 0) csv += _newline;\n        } // Then write out the data\n\n\n        for (var row = 0; row < data.length; row++) {\n          var maxCol = hasHeader ? fields.length : data[row].length;\n          var emptyLine = false;\n          var nullLine = hasHeader ? Object.keys(data[row]).length === 0 : data[row].length === 0;\n\n          if (skipEmptyLines && !hasHeader) {\n            emptyLine = skipEmptyLines === 'greedy' ? data[row].join('').trim() === '' : data[row].length === 1 && data[row][0].length === 0;\n          }\n\n          if (skipEmptyLines === 'greedy' && hasHeader) {\n            var line = [];\n\n            for (var c = 0; c < maxCol; c++) {\n              var cx = dataKeyedByField ? fields[c] : c;\n              line.push(data[row][cx]);\n            }\n\n            emptyLine = line.join('').trim() === '';\n          }\n\n          if (!emptyLine) {\n            for (var col = 0; col < maxCol; col++) {\n              if (col > 0 && !nullLine) csv += _delimiter;\n              var colIdx = hasHeader && dataKeyedByField ? fields[col] : col;\n              csv += safe(data[row][colIdx], col);\n            }\n\n            if (row < data.length - 1 && (!skipEmptyLines || maxCol > 0 && !nullLine)) {\n              csv += _newline;\n            }\n          }\n        }\n\n        return csv;\n      }\n      /** Encloses a value around quotes if needed (makes a value safe for CSV insertion) */\n\n\n      function safe(str, col) {\n        if (typeof str === 'undefined' || str === null) return '';\n        if (str.constructor === Date) return JSON.stringify(str).slice(1, 25);\n        str = str.toString().replace(quoteCharRegex, _quoteChar + _quoteChar);\n        var needsQuotes = typeof _quotes === 'boolean' && _quotes || Array.isArray(_quotes) && _quotes[col] || hasAny(str, Papa.BAD_DELIMITERS) || str.indexOf(_delimiter) > -1 || str.charAt(0) === ' ' || str.charAt(str.length - 1) === ' ';\n        return needsQuotes ? _quoteChar + str + _quoteChar : str;\n      }\n\n      function hasAny(str, substrings) {\n        for (var i = 0; i < substrings.length; i++) if (str.indexOf(substrings[i]) > -1) return true;\n\n        return false;\n      }\n    }\n    /** ChunkStreamer is the base prototype for various streamer implementations. */\n\n\n    function ChunkStreamer(config) {\n      this._handle = null;\n      this._finished = false;\n      this._completed = false;\n      this._input = null;\n      this._baseIndex = 0;\n      this._partialLine = '';\n      this._rowCount = 0;\n      this._start = 0;\n      this._nextChunk = null;\n      this.isFirstChunk = true;\n      this._completeResults = {\n        data: [],\n        errors: [],\n        meta: {}\n      };\n      replaceConfig.call(this, config);\n\n      this.parseChunk = function (chunk, isFakeChunk) {\n        // First chunk pre-processing\n        if (this.isFirstChunk && isFunction(this._config.beforeFirstChunk)) {\n          var modifiedChunk = this._config.beforeFirstChunk(chunk);\n\n          if (modifiedChunk !== undefined) chunk = modifiedChunk;\n        }\n\n        this.isFirstChunk = false; // Rejoin the line we likely just split in two by chunking the file\n\n        var aggregate = this._partialLine + chunk;\n        this._partialLine = '';\n\n        var results = this._handle.parse(aggregate, this._baseIndex, !this._finished);\n\n        if (this._handle.paused() || this._handle.aborted()) return;\n        var lastIndex = results.meta.cursor;\n\n        if (!this._finished) {\n          this._partialLine = aggregate.substring(lastIndex - this._baseIndex);\n          this._baseIndex = lastIndex;\n        }\n\n        if (results && results.data) this._rowCount += results.data.length;\n        var finishedIncludingPreview = this._finished || this._config.preview && this._rowCount >= this._config.preview;\n\n        if (IS_PAPA_WORKER) {\n          global.postMessage({\n            results: results,\n            workerId: Papa.WORKER_ID,\n            finished: finishedIncludingPreview\n          });\n        } else if (isFunction(this._config.chunk) && !isFakeChunk) {\n          this._config.chunk(results, this._handle);\n\n          if (this._handle.paused() || this._handle.aborted()) return;\n          results = undefined;\n          this._completeResults = undefined;\n        }\n\n        if (!this._config.step && !this._config.chunk) {\n          this._completeResults.data = this._completeResults.data.concat(results.data);\n          this._completeResults.errors = this._completeResults.errors.concat(results.errors);\n          this._completeResults.meta = results.meta;\n        }\n\n        if (!this._completed && finishedIncludingPreview && isFunction(this._config.complete) && (!results || !results.meta.aborted)) {\n          this._config.complete(this._completeResults, this._input);\n\n          this._completed = true;\n        }\n\n        if (!finishedIncludingPreview && (!results || !results.meta.paused)) this._nextChunk();\n        return results;\n      };\n\n      this._sendError = function (error) {\n        if (isFunction(this._config.error)) this._config.error(error);else if (IS_PAPA_WORKER && this._config.error) {\n          global.postMessage({\n            workerId: Papa.WORKER_ID,\n            error: error,\n            finished: false\n          });\n        }\n      };\n\n      function replaceConfig(config) {\n        // Deep-copy the config so we can edit it\n        var configCopy = copy(config);\n        configCopy.chunkSize = parseInt(configCopy.chunkSize); // parseInt VERY important so we don't concatenate strings!\n\n        if (!config.step && !config.chunk) configCopy.chunkSize = null; // disable Range header if not streaming; bad values break IIS - see issue #196\n\n        this._handle = new ParserHandle(configCopy);\n        this._handle.streamer = this;\n        this._config = configCopy; // persist the copy to the caller\n      }\n    }\n\n    function NetworkStreamer(config) {\n      config = config || {};\n      if (!config.chunkSize) config.chunkSize = Papa.RemoteChunkSize;\n      ChunkStreamer.call(this, config);\n      var xhr;\n\n      if (IS_WORKER) {\n        this._nextChunk = function () {\n          this._readChunk();\n\n          this._chunkLoaded();\n        };\n      } else {\n        this._nextChunk = function () {\n          this._readChunk();\n        };\n      }\n\n      this.stream = function (url) {\n        this._input = url;\n\n        this._nextChunk(); // Starts streaming\n\n      };\n\n      this._readChunk = function () {\n        if (this._finished) {\n          this._chunkLoaded();\n\n          return;\n        }\n\n        xhr = new XMLHttpRequest();\n\n        if (this._config.withCredentials) {\n          xhr.withCredentials = this._config.withCredentials;\n        }\n\n        if (!IS_WORKER) {\n          xhr.onload = bindFunction(this._chunkLoaded, this);\n          xhr.onerror = bindFunction(this._chunkError, this);\n        }\n\n        xhr.open('GET', this._input, !IS_WORKER); // Headers can only be set when once the request state is OPENED\n\n        if (this._config.downloadRequestHeaders) {\n          var headers = this._config.downloadRequestHeaders;\n\n          for (var headerName in headers) {\n            xhr.setRequestHeader(headerName, headers[headerName]);\n          }\n        }\n\n        if (this._config.chunkSize) {\n          var end = this._start + this._config.chunkSize - 1; // minus one because byte range is inclusive\n\n          xhr.setRequestHeader('Range', 'bytes=' + this._start + '-' + end);\n          xhr.setRequestHeader('If-None-Match', 'webkit-no-cache'); // https://bugs.webkit.org/show_bug.cgi?id=82672\n        }\n\n        try {\n          xhr.send();\n        } catch (err) {\n          this._chunkError(err.message);\n        }\n\n        if (IS_WORKER && xhr.status === 0) this._chunkError();else this._start += this._config.chunkSize;\n      };\n\n      this._chunkLoaded = function () {\n        if (xhr.readyState !== 4) return;\n\n        if (xhr.status < 200 || xhr.status >= 400) {\n          this._chunkError();\n\n          return;\n        }\n\n        this._finished = !this._config.chunkSize || this._start > getFileSize(xhr);\n        this.parseChunk(xhr.responseText);\n      };\n\n      this._chunkError = function (errorMessage) {\n        var errorText = xhr.statusText || errorMessage;\n\n        this._sendError(new Error(errorText));\n      };\n\n      function getFileSize(xhr) {\n        var contentRange = xhr.getResponseHeader('Content-Range');\n\n        if (contentRange === null) {\n          // no content range, then finish!\n          return -1;\n        }\n\n        return parseInt(contentRange.substr(contentRange.lastIndexOf('/') + 1));\n      }\n    }\n\n    NetworkStreamer.prototype = Object.create(ChunkStreamer.prototype);\n    NetworkStreamer.prototype.constructor = NetworkStreamer;\n\n    function FileStreamer(config) {\n      config = config || {};\n      if (!config.chunkSize) config.chunkSize = Papa.LocalChunkSize;\n      ChunkStreamer.call(this, config);\n      var reader, slice; // FileReader is better than FileReaderSync (even in worker) - see http://stackoverflow.com/q/24708649/1048862\n      // But Firefox is a pill, too - see issue #76: https://github.com/mholt/PapaParse/issues/76\n\n      var usingAsyncReader = typeof FileReader !== 'undefined'; // Safari doesn't consider it a function - see issue #105\n\n      this.stream = function (file) {\n        this._input = file;\n        slice = file.slice || file.webkitSlice || file.mozSlice;\n\n        if (usingAsyncReader) {\n          reader = new FileReader(); // Preferred method of reading files, even in workers\n\n          reader.onload = bindFunction(this._chunkLoaded, this);\n          reader.onerror = bindFunction(this._chunkError, this);\n        } else reader = new FileReaderSync(); // Hack for running in a web worker in Firefox\n\n\n        this._nextChunk(); // Starts streaming\n\n      };\n\n      this._nextChunk = function () {\n        if (!this._finished && (!this._config.preview || this._rowCount < this._config.preview)) this._readChunk();\n      };\n\n      this._readChunk = function () {\n        var input = this._input;\n\n        if (this._config.chunkSize) {\n          var end = Math.min(this._start + this._config.chunkSize, this._input.size);\n          input = slice.call(input, this._start, end);\n        }\n\n        var txt = reader.readAsText(input, this._config.encoding);\n        if (!usingAsyncReader) this._chunkLoaded({\n          target: {\n            result: txt\n          }\n        }); // mimic the async signature\n      };\n\n      this._chunkLoaded = function (event) {\n        // Very important to increment start each time before handling results\n        this._start += this._config.chunkSize;\n        this._finished = !this._config.chunkSize || this._start >= this._input.size;\n        this.parseChunk(event.target.result);\n      };\n\n      this._chunkError = function () {\n        this._sendError(reader.error);\n      };\n    }\n\n    FileStreamer.prototype = Object.create(ChunkStreamer.prototype);\n    FileStreamer.prototype.constructor = FileStreamer;\n\n    function StringStreamer(config) {\n      config = config || {};\n      ChunkStreamer.call(this, config);\n      var remaining;\n\n      this.stream = function (s) {\n        remaining = s;\n        return this._nextChunk();\n      };\n\n      this._nextChunk = function () {\n        if (this._finished) return;\n        var size = this._config.chunkSize;\n        var chunk = size ? remaining.substr(0, size) : remaining;\n        remaining = size ? remaining.substr(size) : '';\n        this._finished = !remaining;\n        return this.parseChunk(chunk);\n      };\n    }\n\n    StringStreamer.prototype = Object.create(StringStreamer.prototype);\n    StringStreamer.prototype.constructor = StringStreamer;\n\n    function ReadableStreamStreamer(config) {\n      config = config || {};\n      ChunkStreamer.call(this, config);\n      var queue = [];\n      var parseOnData = true;\n      var streamHasEnded = false;\n\n      this.pause = function () {\n        ChunkStreamer.prototype.pause.apply(this, arguments);\n\n        this._input.pause();\n      };\n\n      this.resume = function () {\n        ChunkStreamer.prototype.resume.apply(this, arguments);\n\n        this._input.resume();\n      };\n\n      this.stream = function (stream$$1) {\n        this._input = stream$$1;\n\n        this._input.on('data', this._streamData);\n\n        this._input.on('end', this._streamEnd);\n\n        this._input.on('error', this._streamError);\n      };\n\n      this._checkIsFinished = function () {\n        if (streamHasEnded && queue.length === 1) {\n          this._finished = true;\n        }\n      };\n\n      this._nextChunk = function () {\n        this._checkIsFinished();\n\n        if (queue.length) {\n          this.parseChunk(queue.shift());\n        } else {\n          parseOnData = true;\n        }\n      };\n\n      this._streamData = bindFunction(function (chunk) {\n        try {\n          queue.push(typeof chunk === 'string' ? chunk : chunk.toString(this._config.encoding));\n\n          if (parseOnData) {\n            parseOnData = false;\n\n            this._checkIsFinished();\n\n            this.parseChunk(queue.shift());\n          }\n        } catch (error) {\n          this._streamError(error);\n        }\n      }, this);\n      this._streamError = bindFunction(function (error) {\n        this._streamCleanUp();\n\n        this._sendError(error);\n      }, this);\n      this._streamEnd = bindFunction(function () {\n        this._streamCleanUp();\n\n        streamHasEnded = true;\n\n        this._streamData('');\n      }, this);\n      this._streamCleanUp = bindFunction(function () {\n        this._input.removeListener('data', this._streamData);\n\n        this._input.removeListener('end', this._streamEnd);\n\n        this._input.removeListener('error', this._streamError);\n      }, this);\n    }\n\n    ReadableStreamStreamer.prototype = Object.create(ChunkStreamer.prototype);\n    ReadableStreamStreamer.prototype.constructor = ReadableStreamStreamer;\n\n    function DuplexStreamStreamer(_config) {\n      var Duplex = stream.Duplex;\n      var config = copy(_config);\n      var parseOnWrite = true;\n      var writeStreamHasFinished = false;\n      var parseCallbackQueue = [];\n      var stream$$1 = null;\n\n      this._onCsvData = function (results) {\n        var data = results.data;\n\n        for (var i = 0; i < data.length; i++) {\n          if (!stream$$1.push(data[i]) && !this._handle.paused()) {\n            // the writeable consumer buffer has filled up\n            // so we need to pause until more items\n            // can be processed\n            this._handle.pause();\n          }\n        }\n      };\n\n      this._onCsvComplete = function () {\n        // node will finish the read stream when\n        // null is pushed\n        stream$$1.push(null);\n      };\n\n      config.step = bindFunction(this._onCsvData, this);\n      config.complete = bindFunction(this._onCsvComplete, this);\n      ChunkStreamer.call(this, config);\n\n      this._nextChunk = function () {\n        if (writeStreamHasFinished && parseCallbackQueue.length === 1) {\n          this._finished = true;\n        }\n\n        if (parseCallbackQueue.length) {\n          parseCallbackQueue.shift()();\n        } else {\n          parseOnWrite = true;\n        }\n      };\n\n      this._addToParseQueue = function (chunk, callback) {\n        // add to queue so that we can indicate\n        // completion via callback\n        // node will automatically pause the incoming stream\n        // when too many items have been added without their\n        // callback being invoked\n        parseCallbackQueue.push(bindFunction(function () {\n          this.parseChunk(typeof chunk === 'string' ? chunk : chunk.toString(config.encoding));\n\n          if (isFunction(callback)) {\n            return callback();\n          }\n        }, this));\n\n        if (parseOnWrite) {\n          parseOnWrite = false;\n\n          this._nextChunk();\n        }\n      };\n\n      this._onRead = function () {\n        if (this._handle.paused()) {\n          // the writeable consumer can handle more data\n          // so resume the chunk parsing\n          this._handle.resume();\n        }\n      };\n\n      this._onWrite = function (chunk, encoding, callback) {\n        this._addToParseQueue(chunk, callback);\n      };\n\n      this._onWriteComplete = function () {\n        writeStreamHasFinished = true; // have to write empty string\n        // so parser knows its done\n\n        this._addToParseQueue('');\n      };\n\n      this.getStream = function () {\n        return stream$$1;\n      };\n\n      stream$$1 = new Duplex({\n        readableObjectMode: true,\n        decodeStrings: false,\n        read: bindFunction(this._onRead, this),\n        write: bindFunction(this._onWrite, this)\n      });\n      stream$$1.once('finish', bindFunction(this._onWriteComplete, this));\n    }\n\n    if (typeof PAPA_BROWSER_CONTEXT === 'undefined') {\n      DuplexStreamStreamer.prototype = Object.create(ChunkStreamer.prototype);\n      DuplexStreamStreamer.prototype.constructor = DuplexStreamStreamer;\n    } // Use one ParserHandle per entire CSV file or string\n\n\n    function ParserHandle(_config) {\n      // One goal is to minimize the use of regular expressions...\n      var FLOAT = /^\\s*-?(\\d*\\.?\\d+|\\d+\\.?\\d*)(e[-+]?\\d+)?\\s*$/i;\n      var ISO_DATE = /(\\d{4}-[01]\\d-[0-3]\\dT[0-2]\\d:[0-5]\\d:[0-5]\\d\\.\\d+([+-][0-2]\\d:[0-5]\\d|Z))|(\\d{4}-[01]\\d-[0-3]\\dT[0-2]\\d:[0-5]\\d:[0-5]\\d([+-][0-2]\\d:[0-5]\\d|Z))|(\\d{4}-[01]\\d-[0-3]\\dT[0-2]\\d:[0-5]\\d([+-][0-2]\\d:[0-5]\\d|Z))/;\n      var self = this;\n      var _stepCounter = 0; // Number of times step was called (number of rows parsed)\n\n      var _rowCounter = 0; // Number of rows that have been parsed so far\n\n      var _input; // The input being parsed\n\n\n      var _parser; // The core parser being used\n\n\n      var _paused = false; // Whether we are paused or not\n\n      var _aborted = false; // Whether the parser has aborted or not\n\n      var _delimiterError; // Temporary state between delimiter detection and processing results\n\n\n      var _fields = []; // Fields are from the header row of the input, if there is one\n\n      var _results = {\n        // The last results returned from the parser\n        data: [],\n        errors: [],\n        meta: {}\n      };\n\n      if (isFunction(_config.step)) {\n        var userStep = _config.step;\n\n        _config.step = function (results) {\n          _results = results;\n          if (needsHeaderRow()) processResults();else // only call user's step function after header row\n            {\n              processResults(); // It's possbile that this line was empty and there's no row here after all\n\n              if (_results.data.length === 0) return;\n              _stepCounter += results.data.length;\n              if (_config.preview && _stepCounter > _config.preview) _parser.abort();else userStep(_results, self);\n            }\n        };\n      }\n      /**\n       * Parses input. Most users won't need, and shouldn't mess with, the baseIndex\n       * and ignoreLastRow parameters. They are used by streamers (wrapper functions)\n       * when an input comes in multiple chunks, like from a file.\n       */\n\n\n      this.parse = function (input, baseIndex, ignoreLastRow) {\n        var quoteChar = _config.quoteChar || '\"';\n        if (!_config.newline) _config.newline = guessLineEndings(input, quoteChar);\n        _delimiterError = false;\n\n        if (!_config.delimiter) {\n          var delimGuess = guessDelimiter(input, _config.newline, _config.skipEmptyLines, _config.comments);\n          if (delimGuess.successful) _config.delimiter = delimGuess.bestDelimiter;else {\n            _delimiterError = true; // add error after parsing (otherwise it would be overwritten)\n\n            _config.delimiter = Papa.DefaultDelimiter;\n          }\n          _results.meta.delimiter = _config.delimiter;\n        } else if (isFunction(_config.delimiter)) {\n          _config.delimiter = _config.delimiter(input);\n          _results.meta.delimiter = _config.delimiter;\n        }\n\n        var parserConfig = copy(_config);\n        if (_config.preview && _config.header) parserConfig.preview++; // to compensate for header row\n\n        _input = input;\n        _parser = new Parser(parserConfig);\n        _results = _parser.parse(_input, baseIndex, ignoreLastRow);\n        processResults();\n        return _paused ? {\n          meta: {\n            paused: true\n          }\n        } : _results || {\n          meta: {\n            paused: false\n          }\n        };\n      };\n\n      this.paused = function () {\n        return _paused;\n      };\n\n      this.pause = function () {\n        _paused = true;\n\n        _parser.abort();\n\n        _input = _input.substr(_parser.getCharIndex());\n      };\n\n      this.resume = function () {\n        _paused = false;\n        self.streamer.parseChunk(_input, true);\n      };\n\n      this.aborted = function () {\n        return _aborted;\n      };\n\n      this.abort = function () {\n        _aborted = true;\n\n        _parser.abort();\n\n        _results.meta.aborted = true;\n        if (isFunction(_config.complete)) _config.complete(_results);\n        _input = '';\n      };\n\n      function testEmptyLine(s) {\n        return _config.skipEmptyLines === 'greedy' ? s.join('').trim() === '' : s.length === 1 && s[0].length === 0;\n      }\n\n      function processResults() {\n        if (_results && _delimiterError) {\n          addError('Delimiter', 'UndetectableDelimiter', 'Unable to auto-detect delimiting character; defaulted to \\'' + Papa.DefaultDelimiter + '\\'');\n          _delimiterError = false;\n        }\n\n        if (_config.skipEmptyLines) {\n          for (var i = 0; i < _results.data.length; i++) if (testEmptyLine(_results.data[i])) _results.data.splice(i--, 1);\n        }\n\n        if (needsHeaderRow()) fillHeaderFields();\n        return applyHeaderAndDynamicTypingAndTransformation();\n      }\n\n      function needsHeaderRow() {\n        return _config.header && _fields.length === 0;\n      }\n\n      function fillHeaderFields() {\n        if (!_results) return;\n\n        for (var i = 0; needsHeaderRow() && i < _results.data.length; i++) for (var j = 0; j < _results.data[i].length; j++) {\n          var header = _results.data[i][j];\n\n          if (_config.trimHeaders) {\n            header = header.trim();\n          }\n\n          _fields.push(header);\n        }\n\n        _results.data.splice(0, 1);\n      }\n\n      function shouldApplyDynamicTyping(field) {\n        // Cache function values to avoid calling it for each row\n        if (_config.dynamicTypingFunction && _config.dynamicTyping[field] === undefined) {\n          _config.dynamicTyping[field] = _config.dynamicTypingFunction(field);\n        }\n\n        return (_config.dynamicTyping[field] || _config.dynamicTyping) === true;\n      }\n\n      function parseDynamic(field, value) {\n        if (shouldApplyDynamicTyping(field)) {\n          if (value === 'true' || value === 'TRUE') return true;else if (value === 'false' || value === 'FALSE') return false;else if (FLOAT.test(value)) return parseFloat(value);else if (ISO_DATE.test(value)) return new Date(value);else return value === '' ? null : value;\n        }\n\n        return value;\n      }\n\n      function applyHeaderAndDynamicTypingAndTransformation() {\n        if (!_results || !_config.header && !_config.dynamicTyping && !_config.transform) return _results;\n\n        for (var i = 0; i < _results.data.length; i++) {\n          var row = _config.header ? {} : [];\n          var j;\n\n          for (j = 0; j < _results.data[i].length; j++) {\n            var field = j;\n            var value = _results.data[i][j];\n            if (_config.header) field = j >= _fields.length ? '__parsed_extra' : _fields[j];\n            if (_config.transform) value = _config.transform(value, field);\n            value = parseDynamic(field, value);\n\n            if (field === '__parsed_extra') {\n              row[field] = row[field] || [];\n              row[field].push(value);\n            } else row[field] = value;\n          }\n\n          _results.data[i] = row;\n\n          if (_config.header) {\n            if (j > _fields.length) addError('FieldMismatch', 'TooManyFields', 'Too many fields: expected ' + _fields.length + ' fields but parsed ' + j, _rowCounter + i);else if (j < _fields.length) addError('FieldMismatch', 'TooFewFields', 'Too few fields: expected ' + _fields.length + ' fields but parsed ' + j, _rowCounter + i);\n          }\n        }\n\n        if (_config.header && _results.meta) _results.meta.fields = _fields;\n        _rowCounter += _results.data.length;\n        return _results;\n      }\n\n      function guessDelimiter(input, newline, skipEmptyLines, comments) {\n        var delimChoices = [',', '\\t', '|', ';', Papa.RECORD_SEP, Papa.UNIT_SEP];\n        var bestDelim, bestDelta, fieldCountPrevRow;\n\n        for (var i = 0; i < delimChoices.length; i++) {\n          var delim = delimChoices[i];\n          var delta = 0,\n              avgFieldCount = 0,\n              emptyLinesCount = 0;\n          fieldCountPrevRow = undefined;\n          var preview = new Parser({\n            comments: comments,\n            delimiter: delim,\n            newline: newline,\n            preview: 10\n          }).parse(input);\n\n          for (var j = 0; j < preview.data.length; j++) {\n            if (skipEmptyLines && testEmptyLine(preview.data[j])) {\n              emptyLinesCount++;\n              continue;\n            }\n\n            var fieldCount = preview.data[j].length;\n            avgFieldCount += fieldCount;\n\n            if (typeof fieldCountPrevRow === 'undefined') {\n              fieldCountPrevRow = fieldCount;\n              continue;\n            } else if (fieldCount > 1) {\n              delta += Math.abs(fieldCount - fieldCountPrevRow);\n              fieldCountPrevRow = fieldCount;\n            }\n          }\n\n          if (preview.data.length > 0) avgFieldCount /= preview.data.length - emptyLinesCount;\n\n          if ((typeof bestDelta === 'undefined' || delta < bestDelta) && avgFieldCount > 1.99) {\n            bestDelta = delta;\n            bestDelim = delim;\n          }\n        }\n\n        _config.delimiter = bestDelim;\n        return {\n          successful: !!bestDelim,\n          bestDelimiter: bestDelim\n        };\n      }\n\n      function guessLineEndings(input, quoteChar) {\n        input = input.substr(0, 1024 * 1024); // max length 1 MB\n        // Replace all the text inside quotes\n\n        var re = new RegExp(escapeRegExp(quoteChar) + '([^]*?)' + escapeRegExp(quoteChar), 'gm');\n        input = input.replace(re, '');\n        var r = input.split('\\r');\n        var n = input.split('\\n');\n        var nAppearsFirst = n.length > 1 && n[0].length < r[0].length;\n        if (r.length === 1 || nAppearsFirst) return '\\n';\n        var numWithN = 0;\n\n        for (var i = 0; i < r.length; i++) {\n          if (r[i][0] === '\\n') numWithN++;\n        }\n\n        return numWithN >= r.length / 2 ? '\\r\\n' : '\\r';\n      }\n\n      function addError(type, code, msg, row) {\n        _results.errors.push({\n          type: type,\n          code: code,\n          message: msg,\n          row: row\n        });\n      }\n    }\n    /** https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions */\n\n\n    function escapeRegExp(string) {\n      return string.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&'); // $& means the whole matched string\n    }\n    /** The core parser implements speedy and correct CSV parsing */\n\n\n    function Parser(config) {\n      // Unpack the config object\n      config = config || {};\n      var delim = config.delimiter;\n      var newline = config.newline;\n      var comments = config.comments;\n      var step = config.step;\n      var preview = config.preview;\n      var fastMode = config.fastMode;\n      var quoteChar;\n      /** Allows for no quoteChar by setting quoteChar to undefined in config */\n\n      if (config.quoteChar === undefined) {\n        quoteChar = '\"';\n      } else {\n        quoteChar = config.quoteChar;\n      }\n\n      var escapeChar = quoteChar;\n\n      if (config.escapeChar !== undefined) {\n        escapeChar = config.escapeChar;\n      } // Delimiter must be valid\n\n\n      if (typeof delim !== 'string' || Papa.BAD_DELIMITERS.indexOf(delim) > -1) delim = ','; // Comment character must be valid\n\n      if (comments === delim) throw 'Comment character same as delimiter';else if (comments === true) comments = '#';else if (typeof comments !== 'string' || Papa.BAD_DELIMITERS.indexOf(comments) > -1) comments = false; // Newline must be valid: \\r, \\n, or \\r\\n\n\n      if (newline !== '\\n' && newline !== '\\r' && newline !== '\\r\\n') newline = '\\n'; // We're gonna need these at the Parser scope\n\n      var cursor = 0;\n      var aborted = false;\n\n      this.parse = function (input, baseIndex, ignoreLastRow) {\n        // For some reason, in Chrome, this speeds things up (!?)\n        if (typeof input !== 'string') throw 'Input must be a string'; // We don't need to compute some of these every time parse() is called,\n        // but having them in a more local scope seems to perform better\n\n        var inputLen = input.length,\n            delimLen = delim.length,\n            newlineLen = newline.length,\n            commentsLen = comments.length;\n        var stepIsFunction = isFunction(step); // Establish starting state\n\n        cursor = 0;\n        var data = [],\n            errors = [],\n            row = [],\n            lastCursor = 0;\n        if (!input) return returnable();\n\n        if (fastMode || fastMode !== false && input.indexOf(quoteChar) === -1) {\n          var rows = input.split(newline);\n\n          for (var i = 0; i < rows.length; i++) {\n            row = rows[i];\n            cursor += row.length;\n            if (i !== rows.length - 1) cursor += newline.length;else if (ignoreLastRow) return returnable();\n            if (comments && row.substr(0, commentsLen) === comments) continue;\n\n            if (stepIsFunction) {\n              data = [];\n              pushRow(row.split(delim));\n              doStep();\n              if (aborted) return returnable();\n            } else pushRow(row.split(delim));\n\n            if (preview && i >= preview) {\n              data = data.slice(0, preview);\n              return returnable(true);\n            }\n          }\n\n          return returnable();\n        }\n\n        var nextDelim = input.indexOf(delim, cursor);\n        var nextNewline = input.indexOf(newline, cursor);\n        var quoteCharRegex = new RegExp(escapeChar.replace(/[-[\\]/{}()*+?.\\\\^$|]/g, '\\\\$&') + quoteChar, 'g');\n        var quoteSearch; // Parser loop\n\n        for (;;) {\n          // Field has opening quote\n          if (input[cursor] === quoteChar) {\n            // Start our search for the closing quote where the cursor is\n            quoteSearch = cursor; // Skip the opening quote\n\n            cursor++;\n\n            for (;;) {\n              // Find closing quote\n              quoteSearch = input.indexOf(quoteChar, quoteSearch + 1); //No other quotes are found - no other delimiters\n\n              if (quoteSearch === -1) {\n                if (!ignoreLastRow) {\n                  // No closing quote... what a pity\n                  errors.push({\n                    type: 'Quotes',\n                    code: 'MissingQuotes',\n                    message: 'Quoted field unterminated',\n                    row: data.length,\n                    // row has yet to be inserted\n                    index: cursor\n                  });\n                }\n\n                return finish();\n              } // Closing quote at EOF\n\n\n              if (quoteSearch === inputLen - 1) {\n                var value = input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar);\n                return finish(value);\n              } // If this quote is escaped, it's part of the data; skip it\n              // If the quote character is the escape character, then check if the next character is the escape character\n\n\n              if (quoteChar === escapeChar && input[quoteSearch + 1] === escapeChar) {\n                quoteSearch++;\n                continue;\n              } // If the quote character is not the escape character, then check if the previous character was the escape character\n\n\n              if (quoteChar !== escapeChar && quoteSearch !== 0 && input[quoteSearch - 1] === escapeChar) {\n                continue;\n              } // Check up to nextDelim or nextNewline, whichever is closest\n\n\n              var checkUpTo = nextNewline === -1 ? nextDelim : Math.min(nextDelim, nextNewline);\n              var spacesBetweenQuoteAndDelimiter = extraSpaces(checkUpTo); // Closing quote followed by delimiter or 'unnecessary spaces + delimiter'\n\n              if (input[quoteSearch + 1 + spacesBetweenQuoteAndDelimiter] === delim) {\n                row.push(input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar));\n                cursor = quoteSearch + 1 + spacesBetweenQuoteAndDelimiter + delimLen;\n                nextDelim = input.indexOf(delim, cursor);\n                nextNewline = input.indexOf(newline, cursor);\n                break;\n              }\n\n              var spacesBetweenQuoteAndNewLine = extraSpaces(nextNewline); // Closing quote followed by newline or 'unnecessary spaces + newLine'\n\n              if (input.substr(quoteSearch + 1 + spacesBetweenQuoteAndNewLine, newlineLen) === newline) {\n                row.push(input.substring(cursor, quoteSearch).replace(quoteCharRegex, quoteChar));\n                saveRow(quoteSearch + 1 + spacesBetweenQuoteAndNewLine + newlineLen);\n                nextDelim = input.indexOf(delim, cursor); // because we may have skipped the nextDelim in the quoted field\n\n                if (stepIsFunction) {\n                  doStep();\n                  if (aborted) return returnable();\n                }\n\n                if (preview && data.length >= preview) return returnable(true);\n                break;\n              } // Checks for valid closing quotes are complete (escaped quotes or quote followed by EOF/delimiter/newline) -- assume these quotes are part of an invalid text string\n\n\n              errors.push({\n                type: 'Quotes',\n                code: 'InvalidQuotes',\n                message: 'Trailing quote on quoted field is malformed',\n                row: data.length,\n                // row has yet to be inserted\n                index: cursor\n              });\n              quoteSearch++;\n              continue;\n            }\n\n            continue;\n          } // Comment found at start of new line\n\n\n          if (comments && row.length === 0 && input.substr(cursor, commentsLen) === comments) {\n            if (nextNewline === -1) // Comment ends at EOF\n              return returnable();\n            cursor = nextNewline + newlineLen;\n            nextNewline = input.indexOf(newline, cursor);\n            nextDelim = input.indexOf(delim, cursor);\n            continue;\n          } // Next delimiter comes before next newline, so we've reached end of field\n\n\n          if (nextDelim !== -1 && (nextDelim < nextNewline || nextNewline === -1)) {\n            row.push(input.substring(cursor, nextDelim));\n            cursor = nextDelim + delimLen;\n            nextDelim = input.indexOf(delim, cursor);\n            continue;\n          } // End of row\n\n\n          if (nextNewline !== -1) {\n            row.push(input.substring(cursor, nextNewline));\n            saveRow(nextNewline + newlineLen);\n\n            if (stepIsFunction) {\n              doStep();\n              if (aborted) return returnable();\n            }\n\n            if (preview && data.length >= preview) return returnable(true);\n            continue;\n          }\n\n          break;\n        }\n\n        return finish();\n\n        function pushRow(row) {\n          data.push(row);\n          lastCursor = cursor;\n        }\n        /**\n                  * checks if there are extra spaces after closing quote and given index without any text\n                  * if Yes, returns the number of spaces\n                  */\n\n\n        function extraSpaces(index) {\n          var spaceLength = 0;\n\n          if (index !== -1) {\n            var textBetweenClosingQuoteAndIndex = input.substring(quoteSearch + 1, index);\n\n            if (textBetweenClosingQuoteAndIndex && textBetweenClosingQuoteAndIndex.trim() === '') {\n              spaceLength = textBetweenClosingQuoteAndIndex.length;\n            }\n          }\n\n          return spaceLength;\n        }\n        /**\n         * Appends the remaining input from cursor to the end into\n         * row, saves the row, calls step, and returns the results.\n         */\n\n\n        function finish(value) {\n          if (ignoreLastRow) return returnable();\n          if (typeof value === 'undefined') value = input.substr(cursor);\n          row.push(value);\n          cursor = inputLen; // important in case parsing is paused\n\n          pushRow(row);\n          if (stepIsFunction) doStep();\n          return returnable();\n        }\n        /**\n         * Appends the current row to the results. It sets the cursor\n         * to newCursor and finds the nextNewline. The caller should\n         * take care to execute user's step function and check for\n         * preview and end parsing if necessary.\n         */\n\n\n        function saveRow(newCursor) {\n          cursor = newCursor;\n          pushRow(row);\n          row = [];\n          nextNewline = input.indexOf(newline, cursor);\n        }\n        /** Returns an object with the results, errors, and meta. */\n\n\n        function returnable(stopped) {\n          return {\n            data: data,\n            errors: errors,\n            meta: {\n              delimiter: delim,\n              linebreak: newline,\n              aborted: aborted,\n              truncated: !!stopped,\n              cursor: lastCursor + (baseIndex || 0)\n            }\n          };\n        }\n        /** Executes the user's step function and resets data & errors. */\n\n\n        function doStep() {\n          step(returnable());\n          data = [];\n          errors = [];\n        }\n      };\n      /** Sets the abort flag */\n\n\n      this.abort = function () {\n        aborted = true;\n      };\n      /** Gets the cursor position */\n\n\n      this.getCharIndex = function () {\n        return cursor;\n      };\n    } // If you need to load Papa Parse asynchronously and you also need worker threads, hard-code\n    // the script path here. See: https://github.com/mholt/PapaParse/issues/87#issuecomment-57885358\n\n\n    function getScriptPath() {\n      var scripts = document.getElementsByTagName('script');\n      return scripts.length ? scripts[scripts.length - 1].src : '';\n    }\n\n    function newWorker() {\n      if (!Papa.WORKERS_SUPPORTED) return false;\n      if (!LOADED_SYNC && Papa.SCRIPT_PATH === null) throw new Error('Script path cannot be determined automatically when Papa Parse is loaded asynchronously. ' + 'You need to set Papa.SCRIPT_PATH manually.');\n      var workerUrl = Papa.SCRIPT_PATH || AUTO_SCRIPT_PATH; // Append 'papaworker' to the search string to tell papaparse that this is our worker.\n\n      workerUrl += (workerUrl.indexOf('?') !== -1 ? '&' : '?') + 'papaworker';\n      var w = new global.Worker(workerUrl);\n      w.onmessage = mainThreadReceivedMessage;\n      w.id = workerIdCounter++;\n      workers[w.id] = w;\n      return w;\n    }\n    /** Callback when main thread receives a message */\n\n\n    function mainThreadReceivedMessage(e) {\n      var msg = e.data;\n      var worker = workers[msg.workerId];\n      var aborted = false;\n      if (msg.error) worker.userError(msg.error, msg.file);else if (msg.results && msg.results.data) {\n        var abort = function () {\n          aborted = true;\n          completeWorker(msg.workerId, {\n            data: [],\n            errors: [],\n            meta: {\n              aborted: true\n            }\n          });\n        };\n\n        var handle = {\n          abort: abort,\n          pause: notImplemented,\n          resume: notImplemented\n        };\n\n        if (isFunction(worker.userStep)) {\n          for (var i = 0; i < msg.results.data.length; i++) {\n            worker.userStep({\n              data: [msg.results.data[i]],\n              errors: msg.results.errors,\n              meta: msg.results.meta\n            }, handle);\n            if (aborted) break;\n          }\n\n          delete msg.results; // free memory ASAP\n        } else if (isFunction(worker.userChunk)) {\n          worker.userChunk(msg.results, handle, msg.file);\n          delete msg.results;\n        }\n      }\n      if (msg.finished && !aborted) completeWorker(msg.workerId, msg.results);\n    }\n\n    function completeWorker(workerId, results) {\n      var worker = workers[workerId];\n      if (isFunction(worker.userComplete)) worker.userComplete(results);\n      worker.terminate();\n      delete workers[workerId];\n    }\n\n    function notImplemented() {\n      throw 'Not implemented.';\n    }\n    /** Callback when worker thread receives a message */\n\n\n    function workerThreadReceivedMessage(e) {\n      var msg = e.data;\n      if (typeof Papa.WORKER_ID === 'undefined' && msg) Papa.WORKER_ID = msg.workerId;\n\n      if (typeof msg.input === 'string') {\n        global.postMessage({\n          workerId: Papa.WORKER_ID,\n          results: Papa.parse(msg.input, msg.config),\n          finished: true\n        });\n      } else if (global.File && msg.input instanceof File || msg.input instanceof Object) // thank you, Safari (see issue #106)\n        {\n          var results = Papa.parse(msg.input, msg.config);\n          if (results) global.postMessage({\n            workerId: Papa.WORKER_ID,\n            results: results,\n            finished: true\n          });\n        }\n    }\n    /** Makes a deep copy of an array or object (mostly) */\n\n\n    function copy(obj) {\n      if (typeof obj !== 'object' || obj === null) return obj;\n      var cpy = Array.isArray(obj) ? [] : {};\n\n      for (var key in obj) cpy[key] = copy(obj[key]);\n\n      return cpy;\n    }\n\n    function bindFunction(f, self) {\n      return function () {\n        f.apply(self, arguments);\n      };\n    }\n\n    function isFunction(func) {\n      return typeof func === 'function';\n    }\n\n    return Papa;\n  });\n});\n\nvar CSVReader =\n/*#__PURE__*/\nfunction (_Component) {\n  _inherits(CSVReader, _Component);\n\n  function CSVReader() {\n    var _getPrototypeOf2;\n\n    var _this;\n\n    _classCallCheck(this, CSVReader);\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    _this = _possibleConstructorReturn(this, (_getPrototypeOf2 = _getPrototypeOf(CSVReader)).call.apply(_getPrototypeOf2, [this].concat(args)));\n\n    _defineProperty(_assertThisInitialized(_assertThisInitialized(_this)), \"handleChangeFile\", function (e) {\n      var _this$props = _this.props,\n          onFileLoaded = _this$props.onFileLoaded,\n          onError = _this$props.onError,\n          _this$props$configOpt = _this$props.configOptions,\n          configOptions = _this$props$configOpt === void 0 ? {} : _this$props$configOpt;\n      var reader = new window.FileReader();\n      var filename = e.target.files[0].name;\n\n      reader.onload = function (event) {\n        papaparse.parse(event.target.result, Object.assign(configOptions, {\n          error: onError,\n          complete: function complete(results) {\n            onFileLoaded(results, filename);\n          }\n        }));\n      };\n\n      reader.readAsText(e.target.files[0]);\n    });\n\n    return _this;\n  }\n\n  _createClass(CSVReader, [{\n    key: \"render\",\n    value: function render() {\n      var _this2 = this;\n\n      var _this$props2 = this.props,\n          inputRef = _this$props2.inputRef,\n          style = _this$props2.style;\n      return React.createElement(\"input\", {\n        type: \"file\",\n        accept: \"text/csv\",\n        ref: inputRef,\n        onChange: function onChange(e) {\n          return _this2.handleChangeFile(e);\n        },\n        style: style\n      });\n    }\n  }]);\n\n  return CSVReader;\n}(Component);\n\n_defineProperty(CSVReader, \"propTypes\", {\n  onFileLoaded: PropTypes.func.isRequired,\n  onError: PropTypes.func,\n  inputRef: PropTypes.object,\n  configOptions: PropTypes.object,\n  style: PropTypes.object\n});\n\nexport { CSVReader };","map":null,"metadata":{},"sourceType":"module"}